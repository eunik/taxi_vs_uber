{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Yellow Taxi Growth\n",
    "\n",
    "#### The objectives of this program:\n",
    "Using the data set that comes from NYC open data of **NYC Yellow Taxi Service** and **Uber Taxi Service** we would like to **analyze the growth** of the NYC Yellow Taxi Service by using the amount of pickups done daily.\n",
    "\n",
    "We will be using correlation between taxi and uber in respective borough to observe the **correlation between the growth rate** of both taxi and uber to help understand how competition impacts pickup amounts. We will also use statistics to help **predict the growth** done within the next few days. We will be using **histograms and line charts** to demonstrate the growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x6cfef28>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import great_circle\n",
    "import matplotlib.dates as mpd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi vs Uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_aug14 = sc.textFile('../yellow_tripdata_2014-08.csv'   , use_unicode=False).filter(lambda x: x != \"\").cache()\n",
    "uber_aug14 = sc.textFile('../uber-raw-data-aug14.csv', use_unicode=False).cache()\n",
    "# list(enumerate(taxi_aug14.first().split(',')))\n",
    "# list(enumerate(uber_aug14.first().split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borough Estimation\n",
    "\n",
    "We will be using midpoints of each respective boughs to where the coordinates of the bus data lies.  \n",
    "We will use the a default distance of 20 miles as the maximum value away from the midterm (that is Staten Island or Manhattan) ends up being around 20 miles.  \n",
    "If both borough overlap we will use the closest distance. Otherwise, if it doesn't fall in borough distance we will consider it to be outside NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "def getlocation(x):\n",
    "    point_coord = (float(x[0]) , float(x[1]))\n",
    "    this_location = rg.search(point_coord, mode = 1)\n",
    "    print(this_location)\n",
    "    if ( this_location[0]['admin2'] == 'Queens County'):\n",
    "        return 'Queens'\n",
    "    else :\n",
    "        return this_location[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion for August 2014 Taxi Data\n",
    "\n",
    "We will clean the data into:  \n",
    "```((boro, pickup, 1)```  \n",
    "Then we will group this data as:  \n",
    "```[boro [(date, count)]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extractTaxi(partId, records):\n",
    "    if partId==0:\n",
    "        records.next()\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        (pickup, boro) = (row[1].split(\" \")[0], getlocation((row[6],row[5])))\n",
    "        if boro in ['The Bronx', 'Brooklyn', 'Queens', 'Manhattan', 'Staten Island']:\n",
    "            yield ((boro, pickup) , 1)\n",
    "        continue\n",
    "\n",
    "trdd = taxi_aug14.mapPartitionsWithIndex(extractTaxi)\\\n",
    "                .reduceByKey(lambda x, y: x+y)\\\n",
    "                .sortBy(lambda x:(x[0][0], x[0][1]))\\\n",
    "                .map(lambda x: (x[0][0], [(x[0][1], x[1])]))\\\n",
    "                .reduceByKey(lambda x, y: (x+y))\n",
    "#trdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion for August 2014 Uber Data\n",
    "\n",
    "Just like the taxi data, we will format the Uber data just the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractUber(partId, records):\n",
    "    if partId==0:\n",
    "        records.next()\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        (pickup, boro) = (row[0].split(\" \")[0],  getlocation((row[1],row[2])))\n",
    "        if boro in ['The Bronx', 'Brooklyn', 'Queens', 'Manhattan', 'Staten Island']:\n",
    "            yield ((boro, pickup) , 1)\n",
    "        continue\n",
    "\n",
    "urdd = uber_aug14.mapPartitionsWithIndex(extractUber)\\\n",
    "                .reduceByKey(lambda x, y: x+y)\\\n",
    "                .map(lambda x: ((x[0][0], datetime.datetime.strptime(x[0][1], \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")), x[1]))\\\n",
    "                .sortBy(lambda x:(x[0][0], x[0][1]))\\\n",
    "                .map(lambda x: (x[0][0], [(x[0][1], x[1])]))\\\n",
    "                .reduceByKey(lambda x, y: (x+y))             \n",
    "#urdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function will get data from either of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets data given a key\n",
    "def get_data(data, key):\n",
    "    # returns ALL values\n",
    "    if key == -1:\n",
    "        return data.values().map(lambda x: list(zip(*x)[1])).collect()\n",
    "    # returns ALL dates\n",
    "    if key == -2:\n",
    "        return data.values().map(lambda x: zip(*x)[0]).collect()[4]\n",
    "    data = zip(*data.collect()[key][1])[1]\n",
    "    if data:\n",
    "        return data\n",
    "    print \"None found\"\n",
    "    return []\n",
    "# don't use index 2 in the actual database because it is 'outside_nyc'\n",
    "lboro = ['Brooklyn', 'Queens', 'Staten Island', 'Manhattan', 'Bronx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Line Graph for Taxi vs Uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_scatter(time, tvalues, uvalues, key):\n",
    "    plt.plot(time, tvalues,'-o', c ='blue', label = 'taxi')\n",
    "    plt.plot(time, uvalues, '-o', c='red', label = 'uber')\n",
    "    plt.title(lboro[key])\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('pickups')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will first make a scatter to observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = list(range(len(get_data(urdd, 0))))\n",
    "\n",
    "for i in range(6):\n",
    "    if i != 2:\n",
    "        make_scatter(datetimes, get_data(trdd, i), get_data(urdd, i), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumilative Line Graph for Taxi vs Uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uvb = [[],[],[],[],[]]\n",
    "tvb = [[],[],[],[],[]]\n",
    "# evaluate the histogram\n",
    "tvb[0] = list(np.histogram(get_data(trdd, 0), bins=30))\n",
    "tvb[1] = list(np.histogram(get_data(trdd, 1), bins=30))\n",
    "tvb[2] = list(np.histogram(get_data(trdd, 3), bins=30))\n",
    "tvb[3] = list(np.histogram(get_data(trdd, 4), bins=30))\n",
    "tvb[4] = list(np.histogram(get_data(trdd, 5), bins=30))\n",
    "\n",
    "uvb[0] = list(np.histogram(get_data(urdd, 0), bins=30))\n",
    "uvb[1] = list(np.histogram(get_data(urdd, 1), bins=30))\n",
    "uvb[2] = list(np.histogram(get_data(urdd, 3), bins=30))\n",
    "uvb[3] = list(np.histogram(get_data(urdd, 4), bins=30))\n",
    "uvb[4] = list(np.histogram(get_data(urdd, 5), bins=30))\n",
    "\n",
    "#evaluate the cumulative\n",
    "tvb[0][0] = np.cumsum(tvb[0][0])\n",
    "tvb[1][0] = np.cumsum(tvb[1][0])\n",
    "tvb[2][0] = np.cumsum(tvb[2][0])\n",
    "tvb[3][0] = np.cumsum(tvb[3][0])\n",
    "tvb[4][0] = np.cumsum(tvb[4][0])\n",
    "\n",
    "uvb[0][0] = np.cumsum(uvb[0][0])\n",
    "uvb[1][0] = np.cumsum(uvb[1][0])\n",
    "uvb[2][0] = np.cumsum(uvb[2][0])\n",
    "uvb[3][0] = np.cumsum(uvb[3][0])\n",
    "uvb[4][0] = np.cumsum(uvb[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative functions\n",
    "def make_accum_graph(key):\n",
    "    if key < 2:\n",
    "        plt.plot(tvb[key][0], tvb[key][1][:-1], c='blue', label = 'taxi')\n",
    "        plt.plot(uvb[key][0], uvb[key][1][:-1], c='red', label = 'uber')\n",
    "        plt.title(lboro[key])\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('pickups')\n",
    "        plt.show()\n",
    "    elif key > 2:\n",
    "        plt.plot(tvb[key-1][0], tvb[key-1][1][:-1], c='blue', label = 'taxi')\n",
    "        plt.plot(uvb[key-1][0], uvb[key-1][1][:-1], c='red', label = 'uber')\n",
    "        plt.title(lboro[key])\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('pickups')\n",
    "        plt.show()\n",
    "    \n",
    "for i in range(6):\n",
    "    make_accum_graph(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth Rate Comparison\n",
    "\n",
    "Then we will make growth rate comparison using histograph of boro based in seperate squares to get a better idea of increase and decrease correlation for both statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_growth(data, key):\n",
    "    sqlc = SQLContext(sc)\n",
    "\n",
    "    data = sc.parallelize(data.collect()[key][1])\n",
    "    df = sqlc.createDataFrame(data, [\"date\", \"value\"])\n",
    "    my_window = Window.partitionBy().orderBy(\"date\")\n",
    "\n",
    "    df = df.withColumn(\"prev_value\", F.lag(df.value).over(my_window))\n",
    "    df = df.withColumn(\"diff\", F.when(F.isnull(((df.value - df.prev_value)/df.prev_value)*100), 0)\n",
    "                                  .otherwise((df.value - df.prev_value)/df.prev_value)*100)\n",
    "    return df.rdd.map(lambda x: x.date.encode(\"utf-8\")).collect(), df.rdd.map(lambda x: x.diff).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_growth_chart(time, tvalues, uvalues, key):\n",
    "    plt.plot(time, tvalues,'-o', c ='blue', label = 'taxi')\n",
    "    plt.plot(time, uvalues, '-o', c='red', label = 'uber')\n",
    "    plt.axhline(linewidth=3, ls = 'dashed')\n",
    "    plt.title(lboro[key])\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('pickups')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datetimes = list(i for i in range(len(get_data(urdd, i))))\n",
    "\n",
    "for i in range(6):\n",
    "    if i != 2:\n",
    "        make_growth_chart(datetimes, get_growth(trdd, i)[1], get_growth(urdd, i)[1], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coeff(slope, intercept, x, y, key):\n",
    "    plt.plot(x, y, 'o', label = 'uber/taxi')\n",
    "    plt.plot(x, intercept+ slope*x, '-', label = 'correlation' )\n",
    "    plt.title(lboro[key])\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('taxi')\n",
    "    plt.ylabel('uber')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "l = list(range(len(get_data(urdd, 0))))\n",
    "\n",
    "for i in range(6):\n",
    "    if i != 2:\n",
    "        #x = scipy.array(get_data(trdd, i))\n",
    "        x = scipy.array(l)\n",
    "        y = scipy.array(get_data(urdd, i))\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        make_coeff(slope, intercept, x, y, i)\n",
    "        print 'r-value: ', r_value\n",
    "        print 'p-value: ', p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['boro', 'days_in_month', 'number_of_pickup']\n",
    "dic_boro = {'bronx': 0, 'brooklyn': 1, 'manhattan': 2, 'outside_nyc': 3, 'queens': 4, 'staten': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Urdd_table = taxi_aug14.mapPartitionsWithIndex(extractUber)\\\n",
    "                .reduceByKey(lambda x, y: x+y)\\\n",
    "                .map(lambda x: ((x[0][0], datetime.datetime.strptime(x[0][1], \"%m/%d/%Y\").strftime(\"%Y-%m-%d\")), x[1]))\\\n",
    "                .sortBy(lambda x:(x[0][0], x[0][1]))\\\n",
    "                .map(lambda x: (dic_boro[x[0][0]], int(datetime.datetime.strptime(x[0][1], \"%Y-%m-%d\").strftime(\"%d\")),x[1]))\n",
    "                               # (x[1]-min_boro[dic_boro[x[0][0]]])/(max_boro[dic_boro[x[0][0]]]- min_boro[dic_boro[x[0][0]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df = pd.DataFrame(Urdd_table.collect(), columns=columns)\\ndf_boro = [[],[],[],[],[],[]]\\nfor i in range(6):\\n    for j in range(len(df)):\\n        if df['boro'][j] == i:\\n            df_boro[i].append(df.loc[j].values)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urdd = Urdd_table.collect()\n",
    "'''df = pd.DataFrame(Urdd_table.collect(), columns=columns)\n",
    "df_boro = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for j in range(len(df)):\n",
    "        if df['boro'][j] == i:\n",
    "            df_boro[i].append(df.loc[j].values)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boro = [[],[],[],[],[],[]]\n",
    "for i in range(6):\n",
    "    for item in df_urdd:\n",
    "        if item[0] == i:\n",
    "            df_boro[i].append(item)\n",
    "for i in range(6):\n",
    "    df_boro[i] = pd.DataFrame(df_boro[i], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4981d3cd06fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_boro\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_of_pickup'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X = [[],[],[],[],[],[]]\n",
    "y =[[],[],[],[],[],[]]\n",
    "X_train=[[],[],[],[],[],[]]\n",
    "X_test=[[],[],[],[],[],[]]\n",
    "y_train=[[],[],[],[],[],[]] \n",
    "y_test=[[],[],[],[],[],[]]\n",
    "\n",
    "for i in range(6):\n",
    "    X[i] = df_boro[i][['boro', 'days_in_month']].values\n",
    "    y[i] = df_boro[i][['number_of_pickup']].values\n",
    "    X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(X[i], y[i], test_size=0.4, random_state=1)\n",
    "    print(X_train[i].shape, X_validation[i].shape, X_test[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0c99c1ca7e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
    "print(X_train.shape, X_validation.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumilative Line Graph for Taxi vs Uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_r = LinearRegression()\n",
    "lasso_r = Lasso()\n",
    "ridge_r = Ridge(alpha=1.0)\n",
    "elastic_r = ElasticNet(alpha=1, l1_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370.65725806 372.57903226 374.50080645 376.42258065 378.34435484\n",
      " 380.26612903 382.18790323 384.10967742 386.03145161 387.95322581\n",
      " 389.875      391.79677419 393.71854839 395.64032258 397.56209677\n",
      " 399.48387097 401.40564516 403.32741935 405.24919355 407.17096774\n",
      " 409.09274194 411.01451613 412.93629032 414.85806452 416.77983871\n",
      " 418.7016129  420.6233871  422.54516129 424.46693548 426.38870968\n",
      " 428.31048387]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-eb499c111ccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mlinear_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlasso_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mridge_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0melastic_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dave\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\linear_model\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 482\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dave\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Users\\Dave\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    linear_r.fit(X_train[i], y_train[i])\n",
    "    lasso_r.fit(X_train[i], y_train[i])\n",
    "    ridge_r.fit(X_train[i], y_train[i])\n",
    "    elastic_r.fit(X_train[i], y_train[i])\n",
    "    print(lasso_r.predict(df_boro[i][['boro', 'days_in_month']].values))\n",
    "'''    print(' accuracy of Linear regression: ',\n",
    "      linear_r.score(X_test[i], y_test[i]),\n",
    "      'accuracy of Lasso: ',\n",
    "      lasso_r.score(X_test[i], y_test[i]),\n",
    "      'accuracy of Ridge regression: ',\n",
    "      ridge_r.score(X_test[i], y_test[i]),\n",
    "      'accuracy of Elastic net: ',\n",
    "      elastic_r.score(X_test[i], y_test[i])\n",
    "     )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
